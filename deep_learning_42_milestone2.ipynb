{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Agoston03/Deep-Learning-42/blob/main/deep_learning_42_milestone2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaVr3Q6x0tKL"
      },
      "source": [
        "This is a homework project in \"Deep Learning a gyakorlatban Python és Lua alapokon\".  \n",
        "The team members are:\n",
        "\n",
        "* Gyulai Gergő László\n",
        "* Horváth Ágoston\n",
        "* Frink Dávid\n",
        "\n",
        "You can read more information about our chosen homework at the link below:  \n",
        "https://www.kaggle.com/competitions/isic-2024-challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTfguNqP_MPw"
      },
      "source": [
        "## Download and setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIs7lHT5_R75"
      },
      "source": [
        "Download Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "3mF86X9w98eu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4645a3c1-2cc7-4a14-9220-07cbcad0760e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle==1.5.12 in /usr/local/lib/python3.10/dist-packages (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle==1.5.12) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle==1.5.12) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle==1.5.12) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle==1.5.12) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle==1.5.12) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle==1.5.12) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle==1.5.12) (2.2.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle==1.5.12) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle==1.5.12) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle==1.5.12) (3.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle==1.5.12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3uje-t7_USk"
      },
      "source": [
        "Configure Kaggle to access the API  \n",
        "**Warning!** You need to copy your own kaggle.json file into Colab in order to validate yourself"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "pH6K85Qn9_k-"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcy_RfSI_b3V"
      },
      "source": [
        "Download the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "roNx7yrj-PeO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6616839-c0df-4cd6-ad7f-e4088d470c16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "isic-2024-challenge.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c isic-2024-challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPTbkCYo_g3Z"
      },
      "source": [
        "Unpacking the data  \n",
        "**Warning!** This might take a few minuttes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlKXjhg4_IC3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06bbb4b4-88f6-47a1-bcf1-d4dd590097e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  isic-2024-challenge.zip\n",
            "replace sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip isic-2024-challenge.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAKVH9CsyP7N"
      },
      "source": [
        "### Preparing train, test and valid set"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gather information about the dataset based on the metadata"
      ],
      "metadata": {
        "id": "kiIoGH76cAo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "KZGq3a8Y3P0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata = pd.read_csv('train-metadata.csv')\n",
        "metadata.head()"
      ],
      "metadata": {
        "id": "zkYDYcfg2_pO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets check the number of benign and malignant data"
      ],
      "metadata": {
        "id": "4ydBP9ivcJPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "benign_data = metadata[metadata['target'] == 0]\n",
        "malignant_data = metadata[metadata['target'] == 1]\n",
        "\n",
        "print(f'Benign images: {len(benign_data)}')\n",
        "print(f'Malignant images: {len(malignant_data)}')"
      ],
      "metadata": {
        "id": "rZbBKaex6FMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benign_ids = benign_data['isic_id'].tolist()\n",
        "malignant_ids = malignant_data['isic_id'].tolist()\n",
        "\n",
        "print(f'Benign images ids: {benign_ids[:5]}')\n",
        "print(f'Malignant images ids: {malignant_ids[:5]}')"
      ],
      "metadata": {
        "id": "Nz5LWD6678Ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_split = 0.1\n",
        "valid_split = 0.1\n",
        "\n",
        "test_benign_ids = benign_ids[:int(len(benign_ids) * test_split)]\n",
        "test_malignant_ids = malignant_ids[:int(len(malignant_ids) * test_split)]\n",
        "\n",
        "valid_benign_ids = benign_ids[int(len(benign_ids) * test_split):int(len(benign_ids) * (test_split + valid_split))]\n",
        "valid_malignant_ids = malignant_ids[int(len(malignant_ids) * test_split):int(len(malignant_ids) * (test_split + valid_split))]\n",
        "\n",
        "train_benign_ids = benign_ids[int(len(benign_ids) * (test_split + valid_split)):]\n",
        "train_malignant_ids = malignant_ids[int(len(malignant_ids) * (test_split + valid_split)):]\n",
        "\n",
        "print(f'Test benign images: {len(test_benign_ids)}')\n",
        "print(f'Test malignant images: {len(test_malignant_ids)}')\n",
        "print(f'Valid benign images: {len(valid_benign_ids)}')\n",
        "print(f'Valid malignant images: {len(valid_malignant_ids)}')\n",
        "print(f'Train benign images: {len(train_benign_ids)}')\n",
        "print(f'Train malignant images: {len(train_malignant_ids)}')"
      ],
      "metadata": {
        "id": "bqTS4zp8lhIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to train another model on the metadata.  \n",
        "The if both models say true, then the leisure is probably malignant.  \n",
        "Here we select the relevant metadata for that model."
      ],
      "metadata": {
        "id": "BegGV7m3-5OI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COLUMNS = [\n",
        "    'clin_size_long_diam_mm',\n",
        "    'tbp_lv_areaMM2',\n",
        "    'tbp_lv_area_perim_ratio',\n",
        "    'tbp_lv_color_std_mean',\n",
        "    'tbp_lv_deltaLBnorm',\n",
        "    'tbp_lv_minorAxisMM',\n",
        "    'tbp_lv_perimeterMM'\n",
        "]\n",
        "\n",
        "malignant_data[COLUMNS].head()"
      ],
      "metadata": {
        "id": "1VSWvJiW1TV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We saple the ids to get a sample data.  \n",
        "We will basically use it to \"test\" each model before training it on huge data."
      ],
      "metadata": {
        "id": "3tGBNH48_KtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "sample_size = 10000\n",
        "\n",
        "benign_sample_ids = random.sample(train_benign_ids, k=min(sample_size, len(train_benign_ids)))\n",
        "malignant_sample_ids = random.sample(train_malignant_ids, k=min(sample_size, len(train_malignant_ids)))\n",
        "\n",
        "print(f'Benign sample ids: {benign_sample_ids[:5]}')\n",
        "print(f'Malignant sample ids: {malignant_sample_ids[:5]}')\n",
        "\n",
        "print(f'Benign sample size: {len(benign_sample_ids)}')\n",
        "print(f'Malignant sample size: {len(malignant_sample_ids)}')"
      ],
      "metadata": {
        "id": "syo_AP9c7nwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loadig the images"
      ],
      "metadata": {
        "id": "943_QU1I-vle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare to load and show images"
      ],
      "metadata": {
        "id": "xRsfJD6qcWYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import io\n",
        "import matplotlib.image as mpimg\n",
        "import h5py"
      ],
      "metadata": {
        "id": "gvV0iEDBRCIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize some of the data we have"
      ],
      "metadata": {
        "id": "jQqakusncaLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# number of rows and colums displayed\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols * 3, nrows * 3)\n",
        "\n",
        "next_benign_pix = [key for key in benign_ids[:int(ncols*nrows/2)]]\n",
        "next_malignant_pix = [key for key in malignant_ids[:int(ncols*nrows/2)]]\n",
        "\n",
        "with h5py.File('train-image.hdf5', 'r') as f:\n",
        "  for i, img_key in enumerate(next_benign_pix + next_malignant_pix):\n",
        "    image_data = f[img_key][()]\n",
        "    image = Image.open(io.BytesIO(image_data))\n",
        "\n",
        "    sp = plt.subplot(nrows, ncols, i + 1)\n",
        "    plt.imshow(image)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QZ5a4wS5OzNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the model"
      ],
      "metadata": {
        "id": "o6GsenPu5gtN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need a **data generator** because the size of the data is enormous.  \n",
        "It is a slightly complicated function and understanding code takes time, so here is **the idea briefly**:  \n",
        "We read data from the file in order, and if there is a **malignant** image, then we **generate more** by rotating it."
      ],
      "metadata": {
        "id": "IXExaPZ1KMJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def next_data_generator(benign_ids, malignant_ids):\n",
        "  ids = benign_ids + malignant_ids\n",
        "  random.shuffle(ids)\n",
        "\n",
        "  while True:\n",
        "    with h5py.File('train-image.hdf5', 'r') as f:\n",
        "      for img_id in ids:\n",
        "        image_data = f[img_id][()]\n",
        "        image = Image.open(io.BytesIO(image_data))\n",
        "        image = image.resize((224, 224))\n",
        "        image_array = np.array(image)\n",
        "\n",
        "        if img_id in malignant_ids:\n",
        "          # Generate more images by rotating the image\n",
        "          for _ in range(3):\n",
        "            rotated_image = image.rotate(random.randint(-10, 10))\n",
        "            rotated_array = np.array(rotated_image)\n",
        "            yield rotated_array, 1\n",
        "        else:\n",
        "          yield image_array, 0"
      ],
      "metadata": {
        "id": "TmcUWi0eSDqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generator(benign_ids, malignant_ids, batch_size=32):\n",
        "  get_next = next_data_generator(benign_ids, malignant_ids)\n",
        "\n",
        "  while True:\n",
        "    batch_data = []\n",
        "    batch_labels = []\n",
        "\n",
        "    for _ in range(batch_size):\n",
        "      image_array, label = next(get_next)\n",
        "      batch_data.append(image_array)\n",
        "      batch_labels.append(label)\n",
        "\n",
        "    yield np.array(batch_data), np.array(batch_labels)"
      ],
      "metadata": {
        "id": "DMXIi1CIAysy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imoprting keras stuff"
      ],
      "metadata": {
        "id": "8ln74RJrMCpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetV2B0\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
      ],
      "metadata": {
        "id": "OozTfFVt5387"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining** the model for training.  \n",
        "We use a **pretrained CNN** model for this assignment.  \n",
        "We will try a few other models later, but this seems enough for now.  \n",
        "What we will definitely have to do later is to experiment with **different loss functions and optimizers**."
      ],
      "metadata": {
        "id": "R82ZXG6TMF4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = EfficientNetV2B0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['recall'])"
      ],
      "metadata": {
        "id": "q8MBUDgfrQH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training** the model.  \n",
        "This might also be the subject of different **modifications** in the future."
      ],
      "metadata": {
        "id": "qIPN-l7pMuca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 5\n",
        "\n",
        "# For now we only train on a small dataset to save resources\n",
        "train_generator = data_generator(benign_sample_ids, malignant_sample_ids, batch_size=batch_size)\n",
        "\n",
        "model.fit(train_generator,\n",
        "          epochs = epochs,\n",
        "          steps_per_epoch = 5,\n",
        "          batch_size = batch_size)"
      ],
      "metadata": {
        "id": "wAlRQyAtAzmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we fill an aray with the **predictions** to simplify the code for the visualizations later."
      ],
      "metadata": {
        "id": "DCrvqQKWOcjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ids = test_benign_ids[:100] + test_malignant_ids\n",
        "predictions_train = np.zeros((len(train_ids), 1))\n",
        "\n",
        "\n",
        "for i, img_id in enumerate(train_ids):\n",
        "  with h5py.File('train-image.hdf5', 'r') as f:\n",
        "    image_data = f[img_id][()]\n",
        "    image = Image.open(io.BytesIO(image_data)).resize((224, 224))\n",
        "    image_array = tf.keras.preprocessing.image.img_to_array(image)\n",
        "    image_array = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "    # Make prediction using the model\n",
        "    prediction = model.predict(image_array, verbose=0)\n",
        "    predictions_train[i] = prediction\n",
        "\n",
        "# Now predictions_train contains the model's predictions for all train images\n",
        "predictions_train.shape"
      ],
      "metadata": {
        "id": "Zl42XKCZ1i4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the **confusion matrix**.  \n",
        "It tells a lot about the model, very intuitively."
      ],
      "metadata": {
        "id": "wzmkrYNNO4hC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "true_labels_train = [0] * 100 + [1] * len(test_malignant_ids)\n",
        "\n",
        "# Convert predictions to binary (0 or 1) using a threshold (e.g., 0.5)\n",
        "predicted_labels_train = (predictions_train > 0.5).astype(int)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(true_labels_train, predicted_labels_train)\n",
        "\n",
        "# Plot the confusion matrix using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Benign', 'Malignant'], yticklabels=['Benign', 'Malignant'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nE2HcNDx1zCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Partial area under the ROC curve** (pAUC) above 80% true positive rate (TPR) for binary classification of malignant examples.\n",
        "\n",
        "The receiver operating characteristic (ROC) curve illustrates the diagnostic ability of a given binary classifier system as its discrimination threshold is varied. However, there are regions in the ROC space where the values of TPR are unacceptable in clinical practice. Systems that aid in diagnosing cancers are required to be highly-sensitive, so this metric focuses on the area under the ROC curve AND above 80% TRP. Hence, scores range from [0.0, 0.2]."
      ],
      "metadata": {
        "id": "IOR6ABxDhKiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "def generate_pAUC_plot(algorithm_probs, true_labels, min_tpr=0.8):\n",
        "    \"\"\"\n",
        "    Generate a plot pAUC above a given minimum TPR for algorithm.\n",
        "\n",
        "    Parameters:\n",
        "        algorithm_probs (list): Predicted probabilities from Algorithm.\n",
        "        true_labels (list): Ground truth binary labels.\n",
        "        min_tpr (float): Minimum TPR threshold for pAUC calculation (default=0.8).\n",
        "    \"\"\"\n",
        "\n",
        "    # Compute ROC curves\n",
        "    fpr_a, tpr_a, _ = roc_curve(true_labels, algorithm_probs)\n",
        "\n",
        "    # Find index of TPR above the min_tpr\n",
        "    min_tpr_idx_a = np.where(tpr_a >= min_tpr)[0]\n",
        "\n",
        "    # Filter FPR and TPR above min_tpr for algorithm\n",
        "    fpr_a_high_tpr, tpr_a_high_tpr = fpr_a[min_tpr_idx_a], tpr_a[min_tpr_idx_a]\n",
        "\n",
        "    # Calculate pAUC above min_tpr\n",
        "    pAUC_a = auc(fpr_a_high_tpr, tpr_a_high_tpr) if len(min_tpr_idx_a) > 0 else 0.0\n",
        "\n",
        "    # Plot ROC curves\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(fpr_a, tpr_a, label=f'Algorithm (pAUC={pAUC_a:.3f})', color='blue', linewidth=2)\n",
        "\n",
        "    # Shade the pAUC region above min_tpr\n",
        "    plt.fill_between(fpr_a_high_tpr, tpr_a_high_tpr, min_tpr, color='blue', alpha=0.2, label='pAUC region')\n",
        "\n",
        "    # Add labels, legend, and grid\n",
        "    plt.axhline(y=min_tpr, color='red', linestyle='--', label=f'Minimum TPR ({min_tpr*100:.0f}%)')\n",
        "    plt.xlabel('False Positive Rate (FPR)')\n",
        "    plt.ylabel('True Positive Rate (TPR)')\n",
        "    plt.title('Partial AUC Above Minimum TPR')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "generate_pAUC_plot(predictions_train, true_labels_train)"
      ],
      "metadata": {
        "id": "yFSLGrdZe8Yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extra:**  \n",
        "For the next assignment we will compare two approaches:  \n",
        "- Gather new data from a different source to enhance the CNN.\n",
        "- Use the metadata to enhance the decisions.  \n",
        "\n",
        "These two might not be compatible, so we need to try and evaluate both."
      ],
      "metadata": {
        "id": "rY0Ny6pYQF2j"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}